# hadoop权威指南

## 1. 初识hadoop

大数据面临的问题：数据量存储量越来越大，读取速度跟不上

解决方案：为了解决这个问题，可以在多个硬盘上各自存储少量数据，在需要时，多个硬盘同时读取，提升读取速度。

解决方案带来的附加问题：

1. 浪费：每个硬盘上存储少量数据又会造成存储空间的浪费，而共享存储空间+用户并不总是同时使用空间，可以解决浪费的问题。
2. 故障：个别硬件会出现故障，需要通过冗余数据副本来避免数据丢失。RAID冗余硬盘阵列和HDFS都是通过冗余来解决这个问题的。
3. 数据的结合使用：一个硬盘读取的数据可能需要和其他多个地方读取来的数据结合使用，需要保障数据的正确性，MapReduce的诞生解决了这个问题。



MapReduce：不适合交互式分析的批处理系统，更适合用户不在场的离现场景。



HBase：使用HDFS作为底层存储的键值存储模型，提供对单行/数据块的在线读写批操作。



YARN：一个集群资源管理系统，允许任何分布式程序（不仅是MapReduce）基于hadoop运行。



hadoop相较于其他系统的优势：

寻址速度（寻址是硬盘磁头移动到指定位置进行读写的过程）的提升远不敌传输速率的提升，访问模式中的寻址操作太多，必然花费更长的读取时间（流数据读取模式主要取决于传输速率），少量数据更新时，传统关系型数据（B树）更有优势，但大量数据更新，MapReduce强得多。

MapReduce应视为关系型数据库管理系统RDBMS的补充，MapReduce适合解决需要批处理方式分析整个数据集的问题，RDBMS适用于索引后数据集的点查询和更新。MapReduce适合一次写入、多次读取的应用，RDBMS适用于持续更新的数据集。

![image-20201025191037792](/Users/xuzhang/gitHub/DATA-PM/notebook/handoop权威指南.assets/image-20201025191037792.png)

hadoop和RDBMS之间的界限很模糊，两者在互相借鉴靠拢，Hive（hadoop的一种）增加了索引和事务的特性， 更像RDBMS。

另一个区别在于他们所才做的数据集的结构化程度，RDBMS主要操作结构化数据，MapReduce操作半结构化和非结构化数据更强，因为它只在处理数据时才对数据进行解释（结构化），即是所谓的“读时模式”，避免了数据加载时解释产生的高开销。

RDBMS的规范性要求保持数据的完整性且不含冗余，MapReduce在处理不规范的大量数据中表现出高性能。

hadoop中的处理模型（MapReduce等）可随数据规模显示型伸缩，集群规模不变的情况下，如果输入的数据量是两倍，处理时间也是两倍，如果集群规模也扩大两倍，那么处理时间不变，SQL查询一般不具备这样的特性。

网格计算：

数据本地化是hadoop数据处理的核心，尽量在计算节点上存储数据，访问的数据量极大时，实现数据的本地快速访问，避免计算节点因为网络带宽的瓶颈问题而闲置。

高性能计算主要采用类似消息传递接口（MPI）的方式进行，虽然赋予了程序员极大的控制权，但需要其显性的控制，手动构造底层的功能模块和高层的数据分析算法，编程难度高。hadoop中，程序员金聪数据模型角度考虑任务的执行即可，无需关心底层的进程协调（如部分进程挂了的情况下如何保证整个计算继续完成），框架会自动检测失败机器并在有效机器上重新执行，因为MapReduce的无共享框架使得各个任务之间彼此独立，执行顺序无关紧要。

## 2. 关于MapReduce

一种模型，用于数据处理，可用各种语言编写，本质是并行的程序，优势在于处理大规模数据集。

难点：如何划分作业、如何协调各个机器处理作业、如何保证可靠性

map任务是提取和处理数据，reduce任务计算数据，输出结果；还需要一个总程序来合并结果。

集群上的可用带宽限制MapReduce作业的数量（作业越多、占用的传输带宽越多） 

#### 数据流

一个MapReduce作业（job）是一个执行工作单元，包括输入数据、MapReduce程序、配置信息；

hadoop将一个作业分为多个任务（task），包括map类任务和reduce类任务；

任务运行在集群节点上，通过YARN调度，失败的任务会在其他节点上重新调度运行。

输入数据会被划分为等长的数据块（分片，input split），每个分片构建一个map任务，该任务处理该分片中的每条数据。

分片与负载：多个分片使得数据整体输入时间减少；较小的分片在性能不同的计算机上可以得到更好的分配（能者多劳、能者快劳），从而提升效率，切片越小，负载平衡的越好，但是过多的分片会增加分片管理、map构建的时间，需要平衡两者。通常一个合理的分片大小趋于HDFS一个节点的大小（规避节点间数据传输），默认128MB，可以根据集群情况调整、或在文件创建时修改。

map任务在存储了输入数据的节点上运行，即数据本地化优化，这样可以节省数据传输带宽（无需节点间传输、机架间传输）。当存储了输入数据的节点已经运行了其他map任务，则从同机架上找没有运行map任务的map槽（slot），并不得不将数据复制传输到其他节点，运行map任务；极少数情况下发生机跨机架任务。

![image-20201027172027599](/Users/xuzhang/gitHub/DATA-PM/notebook/handoop权威指南.assets/image-20201027172027599.png)

reduce任务没有“数据本地化”的概念，因为其输入来自多个mapp任务的输出，数据传输是免不了的。reduce任务的数量可以单独指定，当有多个reduce任务，map的输出也会进行分区，每个reduce任务对应一个分区，分区默认通过hash进行，也可自定义。reduce任务的数量可以有1、n、0三种，有n多个reduce任务时，reduce任务间的数据流称为shuffle混洗；当数据处理（map）可以完全并行（无需混洗）时，会出现无reduce任务的情况，map直接将结果写入HDFS。

![image-20201027173950963](/Users/xuzhang/gitHub/DATA-PM/notebook/handoop权威指南.assets/image-20201027173950963.png)

![image-20201027173959701](/Users/xuzhang/gitHub/DATA-PM/notebook/handoop权威指南.assets/image-20201027173959701.png)

![image-20201027174009376](/Users/xuzhang/gitHub/DATA-PM/notebook/handoop权威指南.assets/image-20201027174009376.png)



combiner函数，是一种优化方案，map任务的输出可以指定给一个combiner函数，它位于map和reduce之间，用于进一步处理map函数的输出，减少数据传输造成的带宽消耗，combiner无法完全代替reduce。

## 3.hadoop分布式文件系统——HDFS

管理网络中跨多台计算机存储的文件系统成为分布式文件系统。HDFS是hadoop自带的分布式文件系统，是一个综合性的文件系统抽象

#### HDFS 设计特点

存储超大文件：几百MB、GB、TB甚至PB级数据

流式数据访问：一次写入、多次读取；读取整个数据集的时间延迟比读取第一条记录的延迟更重要，是主要的优化目标

商用硬件：hadoop集群运行在普通商用硬件构建的集群上，并不依赖昂贵可靠的硬件，商用硬件节点故障率较高，HDFS需要做到遇到部分节点故障时，继续运行，且用户察觉不到明显中断

数据访问的时延：HDFS为高数据吞吐量应用设计，代价是提高时间延迟，时延要去高的应用不合适（HBase可能更好用)

大量的小文件：文件的元数据存储在内存中，一般一个元数据（文件、目录、数据块的存储信息）大概150字节，100w个文件至少需要300MB的内存来存储元数据，数十亿的文件则超出当前硬件的能力

写入与修改文件：HDFS只支持单个写入者，写操作只允许“只添加”模式，在文件末尾追加写数据，不支持修改文件任意位置内容

#### HDFS 相关概念

##### 数据块

磁盘有自己的数据块，是磁盘读写数据的最小单位；文件系统管理磁盘数据块，文件系统块的大小是磁盘块的整数倍；HDFS系统中也有块，默认128MB，比磁盘块大得多（512字节），目的是为了减小寻址开销，HDFS的块中存储一个小于块大小的文件时，不会占据整个存储单元（单一磁盘文件系统中会）。

##### namenode和datanode
节点管理模式，namenode管理节点、datanode工作节点。namenode管理命名空间，维护文件系统树及书内文件和目录，永久保存在本地磁盘上，namenode记录着每个文件所在数据节点的信息，块的位置信息会在系统启动时根据数据节点信息重建，并不永久保存在namenode中。

用户使用客户端，通过namenode和datenode来交互访问文件系统，客户端提供了系统文件接口，用户不必知道namenode和datanode也可以编程。

datanode负责存储和检索数据块，受客户端或namenode调度，定期向namenode发送它存储的块的列表。

namenode损坏或丢失时，所有文件都会丢失，因为无法根据datenode重建文件，所以namenode的容错很重要。hadoop的一种容错机制是将namenode备份在多个文件系统上，本地磁盘写入时，实时同步写入远程挂载的网络文件系统NFS上；另一种办法是运行一个辅助namenode，定期合并编辑日志和命名空间镜像，防止编辑日志过大。它的同步是滞后主节点的，主节点全部挂掉的时候，会不可避免的丢失一点数据。当主节点挂掉，将NFS的namenode元数据复制到辅助namenode，成为新的主namenode运行。

##### 块缓存




