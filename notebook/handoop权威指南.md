# hadoop权威指南

## 1. 初识hadoop

大数据面临的问题：数据量存储量越来越大，读取速度跟不上

解决方案：为了解决这个问题，可以在多个硬盘上各自存储少量数据，在需要时，多个硬盘同时读取，提升读取速度。

解决方案带来的附加问题：

1. 浪费：每个硬盘上存储少量数据又会造成存储空间的浪费，而共享存储空间+用户并不总是同时使用空间，可以解决浪费的问题。
2. 故障：个别硬件会出现故障，需要通过冗余数据副本来避免数据丢失。RAID冗余硬盘阵列和HDFS都是通过冗余来解决这个问题的。
3. 数据的结合使用：一个硬盘读取的数据可能需要和其他多个地方读取来的数据结合使用，需要保障数据的正确性，MapReduce的诞生解决了这个问题。



MapReduce：不适合交互式分析的批处理系统，更适合用户不在场的离现场景。



HBase：使用HDFS作为底层存储的键值存储模型，提供对单行/数据块的在线读写批操作。



YARN：一个集群资源管理系统，允许任何分布式程序（不仅是MapReduce）基于hadoop运行。



hadoop相较于其他系统的优势：

寻址速度（寻址是硬盘磁头移动到指定位置进行读写的过程）的提升远不敌传输速率的提升，访问模式中的寻址操作太多，必然花费更长的读取时间（流数据读取模式主要取决于传输速率），少量数据更新时，传统关系型数据（B树）更有优势，但大量数据更新，MapReduce强得多。

MapReduce应视为关系型数据库管理系统RDBMS的补充，MapReduce适合解决需要批处理方式分析整个数据集的问题，RDBMS适用于索引后数据集的点查询和更新。MapReduce适合一次写入、多次读取的应用，RDBMS适用于持续更新的数据集。

![image-20201025191037792](/Users/xuzhang/gitHub/DATA-PM/notebook/handoop权威指南.assets/image-20201025191037792.png)

hadoop和RDBMS之间的界限很模糊，两者在互相借鉴靠拢，Hive（hadoop的一种）增加了索引和事务的特性， 更像RDBMS。

另一个区别在于他们所才做的数据集的结构化程度，RDBMS主要操作结构化数据，MapReduce操作半结构化和非结构化数据更强，因为它只在处理数据时才对数据进行解释（结构化），即是所谓的“读时模式”，避免了数据加载时解释产生的高开销。

RDBMS的规范性要求保持数据的完整性且不含冗余，MapReduce在处理不规范的大量数据中表现出高性能。

hadoop中的处理模型（MapReduce等）可随数据规模显示型伸缩，集群规模不变的情况下，如果输入的数据量是两倍，处理时间也是两倍，如果集群规模也扩大两倍，那么处理时间不变，SQL查询一般不具备这样的特性。

网格计算：

数据本地化是hadoop数据处理的核心，尽量在计算节点上存储数据，访问的数据量极大时，实现数据的本地快速访问，避免计算节点因为网络带宽的瓶颈问题而闲置。

高性能计算主要采用类似消息传递接口（MPI）的方式进行，虽然赋予了程序员极大的控制权，但需要其显性的控制，手动构造底层的功能模块和高层的数据分析算法，编程难度高。hadoop中，程序员金聪数据模型角度考虑任务的执行即可，无需关心底层的进程协调（如部分进程挂了的情况下如何保证整个计算继续完成），框架会自动检测失败机器并在有效机器上重新执行，因为MapReduce的无共享框架使得各个任务之间彼此独立，执行顺序无关紧要。

## 2. 关于MapReduce

一种模型，用于数据处理，可用各种语言编写，本质是并行的程序，优势在于处理大规模数据集。

难点：如何划分作业、如何协调各个机器处理作业、如何保证可靠性

map任务是提取和处理数据，reduce任务计算数据，输出结果；还需要一个总程序来合并结果。

集群上的可用带宽限制MapReduce作业的数量（作业越多、占用的传输带宽越多） 

#### 数据流

一个MapReduce作业（job）是一个执行工作单元，包括输入数据、MapReduce程序、配置信息；

hadoop将一个作业分为多个任务（task），包括map类任务和reduce类任务；

任务运行在集群节点上，通过YARN调度，失败的任务会在其他节点上重新调度运行。

输入数据会被划分为等长的数据块（分片，input split），每个分片构建一个map任务，该任务处理该分片中的每条数据。

分片与负载：多个分片使得数据整体输入时间减少；较小的分片在性能不同的计算机上可以得到更好的分配（能者多劳、能者快劳），从而提升效率，切片越小，负载平衡的越好，但是过多的分片会增加分片管理、map构建的时间，需要平衡两者。通常一个合理的分片大小趋于HDFS一个节点的大小（规避节点间数据传输），默认128MB，可以根据集群情况调整、或在文件创建时修改。

map任务在存储了输入数据的节点上运行，即数据本地化优化，这样可以节省数据传输带宽（无需节点间传输、机架间传输）。当存储了输入数据的节点已经运行了其他map任务，则从同机架上找没有运行map任务的map槽（slot），并不得不将数据复制传输到其他节点，运行map任务；极少数情况下发生机跨机架任务。

![image-20201027172027599](/Users/xuzhang/gitHub/DATA-PM/notebook/handoop权威指南.assets/image-20201027172027599.png)

reduce任务没有“数据本地化”的概念，因为其输入来自多个mapp任务的输出，数据传输是免不了的。reduce任务的数量可以单独指定，当有多个reduce任务，map的输出也会进行分区，每个reduce任务对应一个分区，分区默认通过hash进行，也可自定义。reduce任务的数量可以有1、n、0三种，有n多个reduce任务时，reduce任务间的数据流称为shuffle混洗；当数据处理（map）可以完全并行（无需混洗）时，会出现无reduce任务的情况，map直接将结果写入HDFS。

![image-20201027173950963](/Users/xuzhang/gitHub/DATA-PM/notebook/handoop权威指南.assets/image-20201027173950963.png)

![image-20201027173959701](/Users/xuzhang/gitHub/DATA-PM/notebook/handoop权威指南.assets/image-20201027173959701.png)

![image-20201027174009376](/Users/xuzhang/gitHub/DATA-PM/notebook/handoop权威指南.assets/image-20201027174009376.png)



combiner函数，是一种优化方案，map任务的输出可以指定给一个combiner函数，它位于map和reduce之间，用于进一步处理map函数的输出，减少数据传输造成的带宽消耗，combiner无法完全代替reduce。

## 3.hadoop分布式文件系统——HDFS

管理网络中跨多台计算机存储的文件系统成为分布式文件系统。HDFS是hadoop自带的分布式文件系统，是一个综合性的文件系统抽象

#### HDFS 设计特点

存储超大文件：几百MB、GB、TB甚至PB级数据

流式数据访问：一次写入、多次读取；读取整个数据集的时间延迟比读取第一条记录的延迟更重要，是主要的优化目标

商用硬件：hadoop集群运行在普通商用硬件构建的集群上，并不依赖昂贵可靠的硬件，商用硬件节点故障率较高，HDFS需要做到遇到部分节点故障时，继续运行，且用户察觉不到明显中断

数据访问的时延：HDFS为高数据吞吐量应用设计，代价是提高时间延迟，时延要去高的应用不合适（HBase可能更好用)

大量的小文件：文件的元数据存储在内存中，一般一个元数据（文件、目录、数据块的存储信息）大概150字节，100w个文件至少需要300MB的内存来存储元数据，数十亿的文件则超出当前硬件的能力

写入与修改文件：HDFS只支持单个写入者，写操作只允许“只添加”模式，在文件末尾追加写数据，不支持修改文件任意位置内容

#### HDFS 相关概念

##### 数据块

磁盘有自己的数据块，是磁盘读写数据的最小单位；文件系统管理磁盘数据块，文件系统块的大小是磁盘块的整数倍；HDFS系统中也有块，默认128MB，比磁盘块大得多（512字节），目的是为了减小寻址开销，HDFS的块中存储一个小于块大小的文件时，不会占据整个存储单元（单一磁盘文件系统中会）。

##### namenode和datanode
节点管理模式，namenode管理节点、datanode工作节点。namenode管理命名空间，维护文件系统树及书内文件和目录，永久保存在本地磁盘上，namenode记录着每个文件所在数据节点的信息，块的位置信息会在系统启动时根据数据节点信息重建，并不永久保存在namenode中。

用户使用客户端，通过namenode和datenode来交互访问文件系统，客户端提供了系统文件接口，用户不必知道namenode和datanode也可以编程。

datanode负责存储和检索数据块，受客户端或namenode调度，定期向namenode发送它存储的块的列表。

namenode损坏或丢失时，所有文件都会丢失，因为无法根据datenode重建文件，所以namenode的容错很重要。hadoop的一种容错机制是将namenode备份在多个文件系统上，本地磁盘写入时，实时同步写入远程挂载的网络文件系统NFS上；另一种办法是运行一个辅助namenode，定期合并编辑日志和命名空间镜像，防止编辑日志过大。它的同步是滞后主节点的，主节点全部挂掉的时候，会不可避免的丢失一点数据。当主节点挂掉，将NFS的namenode元数据复制到辅助namenode，成为新的主namenode运行。

##### 块缓存

datanode通常从磁盘中读取块，但频繁访问的文件，其块可以显式的缓存在datanode的内存中，通过在该datanode上运行任务，实现数据本地化，提高读操作性能。

##### 联邦HDFS

namenode在内存中保存文件系统中每个文件和数据块的引用关系，所以内存成为集群的扩展瓶颈，联邦HDFS允许通过添加namenode来进行扩展，namenode之间相互独立，不进行通信，一个失效也不会影响其他的，每个namenode维护单独的一部分命名空间卷。

##### HDFS的高可用性

namenode依旧存在单点失效的问题，会造成整个hadoop瘫痪

恢复服务需要一个namenode副本并配置datanode和客户端：命名空间的映像导入内存、重演编辑日志、接收到足够多的datanode数据块报告并退出安全模式。对于一个大型集群，上述过程冷启动可能需要30分钟甚至更久。

由于失效是无法完全避免的，提升在计划内的失效恢复时长很重要。Hadoop2配置了一对【活动-备用】namenode，活动namenode失效时，备用namenode接管它的任务，使得hadoop没有明显的中断。

### hadoop文件系统

hadoop有一个抽象文件系统概念，HDFS只是其中一个实现



## 4.集群资源管理系统——YARN

提供请求和使用集群资源的API，构建在HDFS和HBase上，pig、hive等构建在MapReduce、spark 或者 tez上

![image-20201029190317035](/Users/xuzhang/gitHub/DATA-PM/notebook/handoop权威指南.assets/image-20201029190317035.png)



通过两类长期运行的守护进程提供服务：资源管理器（管理集群资源的使用）、节点管理器（运行在集群中所有节点上且能够启动和监控容器）。容器用于执行特定的应用程序的进程，每个容器都有资源限制。

YARN的运行机制：略

YARN的调度机制：略



## 5.hadoop的 I/O操作







## 14.关于Flume

flume用于向hadoop导入基于事件的海量数据。典型例子是利用flume从一组web服务器收集日志文件，然后将文件中的日志事件转移到一个新FDFS汇总文件中，用于进一步处理，其终点（sink）通常为HDFS。flume比较灵活，也可以把数据写到HBase或Solr系统中。

使用flume需要运行一个flume代理（一个java进程），包括source（数据来源）、sink（数据目标）和channel（链接source和sink）。source生产事件，传给channel，channel存储这些事件直至转发给sink，source-channel-sink是Flume的基本构件。

##### 事务与可靠性

flume使用两个独立的事件分别负责从source到channel和从channel到sink。source传递到channel且提交成功，source将标记该文件传输完成。channel到sink类似，当传递失败，事务回滚，等待重新传递。file channel类型的channel具有持久性，重启代理事件也不会丢失，memory channel在缓存中，重启就会丢失，memory channel可以提供更高的吞吐量，根据具体应用决定采取哪种方式。

source的每个事件都一定会到达sink至少一次，会有部分情况导致重复，后续数据处理流程去掉即可。在保证可靠性的前提下，这样处理的成本比采用exactly-once所需要的两阶段提交协议成本更低。

flume以事务为单位批处理事件，提高性能，每个事务只写一次本地磁盘和调用一次fsync

##### HDFS Sink





## 17.关于Hive

一个构建在hadoop上的数据仓库框架。hive的主要目的是能够使用SQL在海量HDFS文件中进行大规模的数据集查询。hive将SQL查询转换为一系列在hadoop集群上运行的作业。hive 把数据组织为表，给HDFS上的数据赋予结构，元数据存储在metastore数据库中。hive能够在原始数据上执行sql查询，是其亮点所在。

hiveQL是SQL的一种，和MySQL语法相近。HiveQL大小写不敏感。

### hive与传统数仓比较

##### 读时模式 vs 写时模式

传统数据库里，表的模式在数据加载时强制确定，加载时发现数据不符合模式，则拒绝加载，数据是在加载（写入数据库）时进行的检查，所以称为“写时模式”；hive在执行查询时才验证数据，称为“读时模式”。

用户可以再两种方法间进行权衡。读时模式使数据加载非常快，因为无需解析数据、序列化并以数据库内部各式存入磁盘，仅仅是文件的复制或移动。写时模式能提升查询性能，数据库可以对列进行索引、压缩，代价是加载数据更久，且查询方式未确定的情况下，无法决定使用哪种索引。

##### 更新、事务和索引

hive被设计为用MapReduce操作HDFS数据，表的更新时通过变换数据后放入新的表中实现的。

在开启事务时，表的插入、更新、删除等操作会保存在增量文件中，定期由metastore运行的MapReduce作业将增量表合并到基表文件中。

hive引入了表级和分区级的锁，由zookeeper透明管理，防止一个进程删除







