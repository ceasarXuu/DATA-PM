# hadoop权威指南

## 1. 初识hadoop

大数据面临的问题：数据量存储量越来越大，读取速度跟不上

解决方案：为了解决这个问题，可以在多个硬盘上各自存储少量数据，在需要时，多个硬盘同时读取，提升读取速度。

解决方案带来的附加问题：

1. 浪费：每个硬盘上存储少量数据又会造成存储空间的浪费，而共享存储空间+用户并不总是同时使用空间，可以解决浪费的问题。
2. 故障：个别硬件会出现故障，需要通过冗余数据副本来避免数据丢失。RAID冗余硬盘阵列和HDFS都是通过冗余来解决这个问题的。
3. 数据的结合使用：一个硬盘读取的数据可能需要和其他多个地方读取来的数据结合使用，需要保障数据的正确性，MapReduce的诞生解决了这个问题。



MapReduce：不适合交互式分析的批处理系统，更适合用户不在场的离现场景。



HBase：使用HDFS作为底层存储的键值存储模型，提供对单行/数据块的在线读写批操作。



YARN：一个集群资源管理系统，允许任何分布式程序（不仅是MapReduce）基于hadoop运行。



hadoop相较于其他系统的优势：

寻址速度（寻址是硬盘磁头移动到指定位置进行读写的过程）的提升远不敌传输速率的提升，访问模式中的寻址操作太多，必然花费更长的读取时间（流数据读取模式主要取决于传输速率），少量数据更新时，传统关系型数据（B树）更有优势，但大量数据更新，MapReduce强得多。

MapReduce应视为关系型数据库管理系统RDBMS的补充，MapReduce适合解决需要批处理方式分析整个数据集的问题，RDBMS适用于索引后数据集的点查询和更新。MapReduce适合一次写入、多次读取的应用，RDBMS适用于持续更新的数据集。

![image-20201025191037792](/Users/xuzhang/gitHub/DATA-PM/notebook/handoop权威指南.assets/image-20201025191037792.png)

hadoop和RDBMS之间的界限很模糊，两者在互相借鉴靠拢，Hive（hadoop的一种）增加了索引和事务的特性， 更像RDBMS。

另一个区别在于他们所才做的数据集的结构化程度，RDBMS主要操作结构化数据，MapReduce操作半结构化和非结构化数据更强，因为它只在处理数据时才对数据进行解释（结构化），即是所谓的“读时模式”，避免了数据加载时解释产生的高开销。

RDBMS的规范性要求保持数据的完整性且不含冗余，MapReduce在处理不规范的大量数据中表现出高性能。

hadoop中的处理模型（MapReduce等）可随数据规模显示型伸缩，集群规模不变的情况下，如果输入的数据量是两倍，处理时间也是两倍，如果集群规模也扩大两倍，那么处理时间不变，SQL查询一般不具备这样的特性。

网格计算：

数据本地化是hadoop数据处理的核心，尽量在计算节点上存储数据，访问的数据量极大时，实现数据的本地快速访问，避免计算节点因为网络带宽的瓶颈问题而闲置。

高性能计算主要采用类似消息传递接口（MPI）的方式进行，虽然赋予了程序员极大的控制权，但需要其显性的控制，手动构造底层的功能模块和高层的数据分析算法，编程难度高。hadoop中，程序员金聪数据模型角度考虑任务的执行即可，无需关心底层的进程协调（如部分进程挂了的情况下如何保证整个计算继续完成），框架会自动检测失败机器并在有效机器上重新执行，因为MapReduce的无共享框架使得各个任务之间彼此独立，执行顺序无关紧要。

## 2. 关于MapReduce

一种模型，用于数据处理，可用各种语言编写，本质是并行的程序，优势在于处理大规模数据集。

难点：如何划分作业、如何协调各个机器处理作业、如何保证可靠性

map任务是提取和处理数据，reduce任务计算数据，输出结果；还需要一个总程序来合并结果。

集群上的可用带宽限制MapReduce作业的数量（作业越多、占用的传输带宽越多） 

#### 数据流

一个MapReduce作业（job）是一个执行工作单元，包括输入数据、MapReduce程序、配置信息；

hadoop将一个作业分为多个任务（task），包括map类任务和reduce类任务；

任务运行在集群节点上，通过YARN调度，失败的任务会在其他节点上重新调度运行。

输入数据会被划分为等长的数据块（分片，input split），每个分片构建一个map任务，该任务处理该分片中的每条数据。

分片与负载：多个分片使得数据整体输入时间减少；较小的分片在性能不同的计算机上可以得到更好的分配（能者多劳、能者快劳），从而提升效率，切片越小，负载平衡的越好，但是过多的分片会增加分片管理、map构建的时间，需要平衡两者。通常一个合理的分片大小趋于HDFS一个节点的大小（规避节点间数据传输），默认128MB，可以根据集群情况调整、或在文件创建时修改。

map任务在存储了输入数据的节点上运行，即数据本地化优化，这样可以节省数据传输带宽（无需节点间传输、机架间传输）。当存储了输入数据的节点已经运行了其他map任务，则从同机架上找没有运行map任务的map槽（slot），并不得不将数据复制传输到其他节点，运行map任务；极少数情况下发生机跨机架任务。

![image-20201027172027599](/Users/xuzhang/gitHub/DATA-PM/notebook/handoop权威指南.assets/image-20201027172027599.png)

reduce任务没有“数据本地化”的概念，因为其输入来自多个mapp任务的输出，数据传输是免不了的。reduce任务的数量可以单独指定，当有多个reduce任务，map的输出也会进行分区，每个reduce任务对应一个分区，分区默认通过hash进行，也可自定义。reduce任务的数量可以有1、n、0三种，有n多个reduce任务时，reduce任务间的数据流称为shuffle混洗；当数据处理（map）可以完全并行（无需混洗）时，会出现无reduce任务的情况，map直接将结果写入HDFS。

![image-20201027173950963](/Users/xuzhang/gitHub/DATA-PM/notebook/handoop权威指南.assets/image-20201027173950963.png)

![image-20201027173959701](/Users/xuzhang/gitHub/DATA-PM/notebook/handoop权威指南.assets/image-20201027173959701.png)

![image-20201027174009376](/Users/xuzhang/gitHub/DATA-PM/notebook/handoop权威指南.assets/image-20201027174009376.png)








